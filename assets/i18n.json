{
  "EN": {
    "app_title": "Torchvision Transforms Playground",
    "app_subtitles": [
      "Explore transformations with [torchvision](https://docs.pytorch.org/vision/stable/transforms) and generate a ready-to-use pipeline. This interactive sandbox helps you clearly see the actual effect of transformations (e.g. filters) on your images, and fine-tune your settings before integrating them into the computer vision model training (e.g. data augmentation)."
    ],
    "language_label": "Language",
    "subtitle_label": "Description",
    "disable_all": "Disable all transforms",
    "globals_title": "Global settings",
    "variants_label": "MIX variants per image",
    "seed_label": "Seed",
    "reseed_label": "Re-seed each variant (reproducible)",
    "status_label": "Active sections",
    "code_label": "Torchvision Compose code (live)",
    "upload_section": "1) Upload images",
    "upload_label": "Upload (multi-images)",
    "apply": "Generate (1 example / transform + FINAL MIX)",
    "results_section": "2) Results",
    "results_label": "Results",
    "sidebar_title": "Controls",
    "docs_prefix": "Docs:",
    "sections": {
      "geometric": "Geometric",
      "photometric": "Photometric",
      "policies": "Auto-Augmentation policies",
      "random_applied": "Randomly-applied",
      "tensor_bonus": "Miscellaneous, Bonus"
    },

    "sim_title": "Similarity",
    "sim_enable_label": "Compute similarity scores",
    "sim_metrics_label": "Metrics",
    "sim_size_label": "Score resize (px)",
    "sim_about_title": "About similarity scores",
    "sim_about_md": "### Similarity scores — how to read them\n\nThese scores compare the **original image** to a **transformed output**.\n\n#### 1) Why a “score resize” is needed\nMost **pixel-based** metrics require the two images to have the **same resolution** (same H×W). But many transforms change size (crop/resize/pad/five-crop).\nSo, for scoring, we:\n- **Resize both images to a fixed square** (e.g. 256×256)\n- Then compute metrics on these resized versions\n\n**How to choose the scoring size:**\n- **128 px**: fastest, but less sensitive to small details\n- **256 px**: good default (balance)\n- **512 px**: more sensitive to details, slower\n\nNote: resizing is only for scoring; it does **not** change the displayed results.\n\n---\n\n#### 2) SSIM — *Structural Similarity Index Measure*\n**What it measures:** similarity of **structure/contrast/luminance** (closer to “human perception” than raw pixel error).\n\n**Important (implementation detail):** this app uses a **lightweight global SSIM approximation** (single-window statistics). It is stable and dependency-free, but it is not the full sliding-window SSIM used in some libraries.\n\n**Range:** typically **0..1** (can be negative in rare edge cases)\n- **1.00**: identical\n- **0.95+**: extremely similar (tiny changes)\n- **0.85–0.95**: similar, visible but moderate changes\n- **0.70–0.85**: noticeable changes\n- **< 0.70**: strong changes (crop, heavy blur, big color shifts, strong geometry)\n\n**Good for:** blur, compression artifacts, mild color/contrast changes.\n**Not great for:** geometric transforms (rotation, crop) — SSIM can drop a lot even if the image “content” is the same but shifted.\n\n---\n\n#### 3) aHash — *Average Hash* (perceptual hash)\n**What it measures:** a tiny **fingerprint** of the image based on low-frequency appearance.\n\nWe convert hash distance into a **0..1 similarity** score:\n- **1.00**: same fingerprint\n- **0.90+**: very close\n- **0.75–0.90**: moderate changes\n- **< 0.75**: strong change\n\n**Good for:** a quick “looks roughly the same” check.\n**Limitations:** can be fooled by some changes; does not reflect fine details.\n\n---\n\n#### 4) MSE — *Mean Squared Error*\n**What it measures:** average squared pixel difference (after score resize).\n\n**Scale:** **0..+∞** (lower is better)\n- **0**: identical\n\n**Rule of thumb (with pixels normalized to 0..1):**\n- **< 0.001**: tiny difference\n- **0.001–0.01**: small to moderate difference\n- **> 0.01**: large difference\n\n**Important:** MSE is strict. A small shift/rotation can create a large MSE even if the image still looks “the same”.\n\n---\n\n#### 5) PSNR — *Peak Signal-to-Noise Ratio*\n**What it measures:** a log-scale view of pixel error. It is derived from MSE.\n\n**Scale:** in **dB** (higher is better)\n- **∞**: identical (when MSE = 0)\n\n**Common thresholds (after score resize):**\n- **> 40 dB**: almost indistinguishable\n- **30–40 dB**: good quality / mild degradation\n- **20–30 dB**: visible degradation\n- **< 20 dB**: strong degradation\n\n**Good for:** compression/noise/blur comparisons.\n**Limitations:** like MSE, it is very sensitive to geometry shifts.\n\n---\n\n#### 6) CLIP — *semantic similarity* (optional)\n**What it measures:** similarity of **high-level content** using CLIP image embeddings (cosine similarity).\n\n**Model used (this app):** `open_clip` **ViT-B-32** (pretrained: **laion2b_s34b_b79k**).\n\n**Range:** typically **-1..1** (often **0..1** for related images)\n- Higher = more semantically similar (same subject / same scene)\n\n**Good for:** geometric transforms (crop, rotation, perspective) where pixel metrics drop but the **subject remains**.\n\n**Note:** CLIP requires the optional dependency `open_clip`. If it is not available, the app may hide/ignore this metric.\n\n---\n\n#### Quick examples\n- **JPEG compression (mild):** SSIM ~0.90–0.98, PSNR ~30–40 dB\n- **Strong blur:** SSIM drops (e.g. 0.70–0.90), PSNR may still be moderate\n- **Crop / rotation:** SSIM & PSNR often drop a lot, while CLIP can stay relatively high if the subject remains\n\nPixel-based metrics assume spatial alignment. Geometric transforms may produce low pixel scores even if images look visually similar.",
    "sim_legend_md": "When enabled, scores appear in captions (example: `SSIM 0.82 | aHash 0.95 | CLIP 0.77 | PSNR 28.4dB | MSE 0.0042`)."
  },

  "FR": {
    "app_title": "Torchvision Transforms Playground",
    "app_subtitles": [
      "Explorer les transformations avec [torchvision](https://docs.pytorch.org/vision/stable/transforms) et générer une pipeline prête à l’emploi.\n Ce bac à sable vous aide à voir concrètement l’effet des transformations (ex. filtres) sur vos images, et à ajuster vos réglages avant de les intégrer à l’entraînement d’un modèle de vision par ordinateur (ex. augmentation de données)."
    ],
    "language_label": "Langue",
    "subtitle_label": "Description",
    "disable_all": "Tout désactiver",
    "globals_title": "Paramètres généraux",
    "variants_label": "Variantes (MIX) par image",
    "seed_label": "Seed",
    "reseed_label": "Re-seed à chaque variante (reproductible)",
    "status_label": "Sections actives",
    "code_label": "Code torchvision Compose (live)",
    "upload_section": "1) Déposer des images",
    "upload_label": "Upload (multi-images)",
    "apply": "Générer (1 exemple / transformation + MIX FINAL)",
    "results_section": "2) Résultats",
    "results_label": "Résultats",
    "sidebar_title": "Contrôles",
    "docs_prefix": "Doc :",
    "sections": {
      "geometric": "Géométriques",
      "photometric": "Photométriques",
      "policies": "Politiques d'auto-augmentation",
      "random_applied": "Transformations appliquées aléatoirement",
      "tensor_bonus": "Divers, Bonus"
    },

    "sim_title": "Similarité",
    "sim_enable_label": "Calculer les scores de similarité",
    "sim_metrics_label": "Métriques",
    "sim_size_label": "Taille de scoring (px)",
    "sim_about_title": "À propos des scores de similarité",
    "sim_about_md": "### Scores de similarité — comment les interpréter ?\n\nCes scores comparent l’**image originale** à une **image transformée**.\n\n#### 1) Pourquoi une « taille de scoring » est nécessaire ?\nLa plupart des métriques **basées sur les pixels** exigent que les deux images aient **la même résolution** (même H×L). Cependant beaucoup de transformations changent la taille (crop/resize/pad/five-crop).\nDonc pour scorer, on :\n- **redimensionne les deux images en carré** (ex. 256×256)\n- On calcule ensuite les métriques sur ces versions redimensionnées\n\n**Comment choisir la taille de scoring ? :**\n- **128 px** : très rapide, mais moins sensible aux petits détails\n- **256 px** : bon défaut (équilibre)\n- **512 px** : plus sensible aux détails, plus lent\n\nNote : ce resize sert uniquement au score ; il ne change **pas** les images affichées.\n\n---\n\n#### 2) SSIM — *Structural Similarity Index Measure* (indice de similarité structurelle)\n**Définition :** la similarité de la **structure / contraste / luminance** (souvent plus proche de la perception humaine qu’une erreur pixel brute).\n\n**Important (détail d’implémentation) :** cette application utilise une **approximation SSIM globale légère** (statistiques sur une « fenêtre » unique pas de fenêtres glissantes).\n\n**Échelle :** en pratique **0..1** (peut être négatif dans de rares cas)\n- **1.00** : identiques\n- **≥ 0.95** : extrêmement proches (différences infimes)\n- **0.85–0.95** : proches, changements visibles mais modérés\n- **0.70–0.85** : changements nets\n- **< 0.70** : gros changements (crop, blur fort, grandes variations de couleur, grosses déformations)\n\n**Efficace pour :** blur, artefacts de compression, petits changements de couleur/contraste.\n**Moins adapté :** transformations géométriques (rotation, crop) — SSIM peut chuter fortement même si le contenu « est le même » mais déplacé (effets de géométrie).\n\n---\n\n#### 3) aHash — *Average Hash* (hash perceptuel)\n**Définition :** une petite **empreinte** basée sur l’apparence globale (basses fréquences).\n\nOn convertit la distance de hash en similarité **0..1** :\n- **1.00** : empreinte identique\n- **≥ 0.90** : très proche\n- **0.75–0.90** : changements modérés\n- **< 0.75** : changement important\n\n**Parfait pour :** une estimation rapide « est-ce que les images se ressemblent globalement ? ».\n**Limites :** ne capture pas bien les détails fins.\n\n---\n\n#### 4) MSE — *Mean Squared Error* (erreur quadratique moyenne)\n**Définition :** la moyenne des écarts de pixel, élevés au carré (après redimensionnement pour le scoring).\n\n**Échelle :** **0..+∞** (plus bas = meilleur)\n- **0** : identiques\n\n**Ordres de grandeur (si pixels normalisés en 0..1) :**\n- **< 0.001** : différence minime\n- **0.001–0.01** : petite à modérée\n- **> 0.01** : forte différence\n\n**Important :** MSE est très “strict”. Un léger décalage/rotation peut produire une MSE élevée, même si l’image paraît proche.\n\n---\n\n#### 5) PSNR — *Peak Signal-to-Noise Ratio* (rapport signal/bruit crête)\n**Définition :** une version en échelle logarithmique de l’erreur pixel (dérivée de la MSE).\n\n**Unité :** **dB** (plus haut = meilleur)\n- **∞** : identiques (quand MSE = 0)\n\n**Seuils courants (après resize de scoring) :**\n- **> 40 dB** : quasi indiscernable\n- **30–40 dB** : bonne qualité / dégradation légère\n- **20–30 dB** : dégradation visible\n- **< 20 dB** : forte dégradation\n\n**Parfait pour :** compression, bruit, blur.\n**Limites :** comme la MSE, très sensible aux transformations géométriques.\n\n---\n\n#### 6) CLIP — *similarité sémantique* (optionnel)\n**Définition :** la similarité du **contenu haut niveau** (sujet / scène) via des embeddings d’images pré-calculés CLIP (cosine similarity).\n\n**Modèle utilisé (dans cette app) :** `open_clip` **ViT-B-32** (pré-entraîné : **laion2b_s34b_b79k**).\n\n**Échelle :** généralement **-1..1** (souvent **0..1** pour des images liées)\n- Plus haut = très similaire sémantiquement\n\n**Parfait pour :** transformations géométriques (crop, rotation, perspective) où les métriques pixel chutent, mais où le **sujet et/ou le thème reste présent**.\n\n**Note :** CLIP dépend de `open_clip`. Si ce module n’est pas installé, l’app peut ignorer/masquer cette métrique.\n\n---\n\n#### Exemples rapides\n- **Compression JPEG (légère) :** SSIM ~0.90–0.98, PSNR ~30–40 dB\n- **Flou fort :** SSIM baisse (ex. 0.70–0.90), PSNR peut rester moyen\n- **Crop / rotation :** SSIM et PSNR chutent souvent, tandis que CLIP peut rester relativement haut si le sujet est toujours présent\n\nLes métriques basées sur les pixels supposent un alignement spatial. Les transformations géométriques peuvent produire des scores pixel très faibles même si les images semblent similaires à l’œil humain (Cf. score CLIP).",
    "sim_legend_md": "Quand le module de métriques est activé, les scores apparaissent dans les légendes (ex : `SSIM 0.82 | aHash 0.95 | CLIP 0.77 | PSNR 28.4dB | MSE 0.0042`)."
  }
}